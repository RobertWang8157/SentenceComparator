{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /Users/johnny/anaconda3/lib/python3.10/site-packages (2.2.2)\r\n",
      "Requirement already satisfied: sentencepiece in /Users/johnny/anaconda3/lib/python3.10/site-packages (from sentence-transformers) (0.1.99)\r\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/johnny/anaconda3/lib/python3.10/site-packages (from sentence-transformers) (2.1.0)\r\n",
      "Requirement already satisfied: numpy in /Users/johnny/anaconda3/lib/python3.10/site-packages (from sentence-transformers) (1.23.5)\r\n",
      "Requirement already satisfied: tqdm in /Users/johnny/anaconda3/lib/python3.10/site-packages (from sentence-transformers) (4.64.1)\r\n",
      "Requirement already satisfied: nltk in /Users/johnny/anaconda3/lib/python3.10/site-packages (from sentence-transformers) (3.7)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/johnny/anaconda3/lib/python3.10/site-packages (from sentence-transformers) (4.35.0)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/johnny/anaconda3/lib/python3.10/site-packages (from sentence-transformers) (0.17.3)\r\n",
      "Requirement already satisfied: torchvision in /Users/johnny/anaconda3/lib/python3.10/site-packages (from sentence-transformers) (0.16.0)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/johnny/anaconda3/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\r\n",
      "Requirement already satisfied: scipy in /Users/johnny/anaconda3/lib/python3.10/site-packages (from sentence-transformers) (1.10.0)\r\n",
      "Requirement already satisfied: filelock in /Users/johnny/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/johnny/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/johnny/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (22.0)\r\n",
      "Requirement already satisfied: fsspec in /Users/johnny/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.10.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/johnny/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.4.0)\r\n",
      "Requirement already satisfied: requests in /Users/johnny/anaconda3/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\r\n",
      "Requirement already satisfied: sympy in /Users/johnny/anaconda3/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/johnny/anaconda3/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\r\n",
      "Requirement already satisfied: networkx in /Users/johnny/anaconda3/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (2.8.4)\r\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /Users/johnny/anaconda3/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.14.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/johnny/anaconda3/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.7.9)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/johnny/anaconda3/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.0)\r\n",
      "Requirement already satisfied: click in /Users/johnny/anaconda3/lib/python3.10/site-packages (from nltk->sentence-transformers) (8.0.4)\r\n",
      "Requirement already satisfied: joblib in /Users/johnny/anaconda3/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.1.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/johnny/anaconda3/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (2.2.0)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/johnny/anaconda3/lib/python3.10/site-packages (from torchvision->sentence-transformers) (9.4.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/johnny/anaconda3/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.1)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/johnny/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.14)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/johnny/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/johnny/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\r\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/johnny/anaconda3/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/johnny/anaconda3/lib/python3.10/site-packages/mpmath-1.2.1-py3.10.egg (from sympy->torch>=1.6.0->sentence-transformers) (1.2.1)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T01:21:22.571099Z",
     "start_time": "2023-11-15T01:21:16.321936Z"
    }
   },
   "id": "18f75d4be9068c53"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mysql-connector-python in /Users/johnny/anaconda3/lib/python3.10/site-packages (8.1.0)\r\n",
      "Collecting protobuf<=4.21.12,>=4.21.1\r\n",
      "  Using cached protobuf-4.21.12-cp37-abi3-macosx_10_9_universal2.whl (486 kB)\r\n",
      "Installing collected packages: protobuf\r\n",
      "  Attempting uninstall: protobuf\r\n",
      "    Found existing installation: protobuf 3.20.3\r\n",
      "    Uninstalling protobuf-3.20.3:\r\n",
      "      Successfully uninstalled protobuf-3.20.3\r\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow 2.10.0 requires libclang>=13.0.0, which is not installed.\r\n",
      "tensorflow 2.10.0 requires tensorflow-io-gcs-filesystem>=0.23.1, which is not installed.\r\n",
      "tensorflow 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.12 which is incompatible.\r\n",
      "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.21.12 which is incompatible.\r\n",
      "tensorboard 2.10.0 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.21.12 which is incompatible.\u001B[0m\u001B[31m\r\n",
      "\u001B[0mSuccessfully installed protobuf-4.21.12\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mysql-connector-python"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-15T01:21:43.299377Z",
     "start_time": "2023-11-15T01:21:33.664790Z"
    }
   },
   "id": "68891831d40dc6ef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server running on port 8000\n",
      "Input sentence: go to the church\n",
      "Most tag: ASK_TO_PLAY\n",
      "Most similar response: Come on\n",
      "similarity: tensor([[0.4867]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [06/Dec/2023 15:15:42] \"POST / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: go to the church\n",
      "Most tag: ASK_TO_PLAY\n",
      "Most similar response: Come on\n",
      "similarity: tensor([[0.4867]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [06/Dec/2023 15:16:42] \"POST / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from http.server import BaseHTTPRequestHandler, HTTPServer\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import mysql.connector\n",
    "import json\n",
    "\n",
    "def connect_to_database():\n",
    "    connection = mysql.connector.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"root\",\n",
    "        password=\"3659215fF\",\n",
    "        database=\"handle_together\"\n",
    "    )\n",
    "    return connection\n",
    "\n",
    "def send_json_response(self, status_code, data):\n",
    "    # Convert status_code to integer\n",
    "    status_code = int(status_code)\n",
    "\n",
    "    # Set up the HTTP response\n",
    "    self.send_response(status_code)\n",
    "    self.send_header(\"Content-type\", \"application/json\")\n",
    "    self.end_headers()\n",
    "\n",
    "    # Convert the data to JSON\n",
    "    json_response = json.dumps(data)\n",
    "\n",
    "    # Send the JSON response\n",
    "    self.wfile.write(json_response.encode('utf-8'))\n",
    "\n",
    "class WebServerHandler(BaseHTTPRequestHandler):\n",
    "\n",
    "    def do_POST(self):       \n",
    "        # Read the content length from the request headers\n",
    "        content_length = int(self.headers['Content-Length'])\n",
    "\n",
    "        # Read the JSON data from the request body\n",
    "        post_data = self.rfile.read(content_length)\n",
    "        json_data_list = json.loads(post_data.decode('utf-8'))\n",
    "\n",
    "        if json_data_list:\n",
    "            json_data = json_data_list[0]\n",
    "            # Now json_data contains the parameters sent in the JSON format\n",
    "            tag_array = json_data.get('tag_array', [])\n",
    "            subject_array = json_data.get('subject_array', [])\n",
    "            input_sentence = json_data.get('input_sentence', '')       \n",
    "\n",
    "        # Load the Sentence Transformer model\n",
    "        model = SentenceTransformer(\"shibing624/text2vec-base-chinese\")\n",
    "\n",
    "        # Fetch distinct subject codes from intent_type table\n",
    "        connection = connect_to_database()\n",
    "        cursor = connection.cursor()\n",
    "\n",
    "        # Use parameterized query to avoid SQL injection\n",
    "        # query = \"SELECT tag, content FROM intent_training_data WHERE tag IN ({}) AND subject IN ({})\".format(','.join(['%s' for _ in tag_array]), ','.join(['%s' for _ in subject_array]))\n",
    "        if tag_array and any(tag_array):\n",
    "            tag_condition = \"tag IN ({})\".format(','.join(['%s' for _ in tag_array]))\n",
    "        else:\n",
    "            tag_condition = \"1=1\"  # Always true if tag_array is empty or None\n",
    "        \n",
    "        query = \"SELECT tag, content FROM intent_training_data WHERE {} AND subject IN ({})\".format(tag_condition, ','.join(['%s' for _ in subject_array]))\n",
    "\n",
    "        params = tag_array + subject_array\n",
    "        cursor.execute(query, params)\n",
    "        rows = cursor.fetchall()\n",
    "        candidate_responses_tags = [row[0] for row in rows]\n",
    "        candidate_responses = [row[1] for row in rows]\n",
    "\n",
    "        cursor.close()\n",
    "        connection.close()\n",
    "\n",
    "        # Encode input sentence and candidate responses\n",
    "        input_embedding = model.encode([input_sentence])\n",
    "        response_embeddings = model.encode(candidate_responses)\n",
    "\n",
    "        # Calculate cosine similarity between input and responses\n",
    "        similarities = util.pytorch_cos_sim(input_embedding, response_embeddings)[0]\n",
    "        \n",
    "        similarity = util.pytorch_cos_sim(input_embedding, response_embeddings)\n",
    "\n",
    "        # Get the index of the most similar response\n",
    "        most_similar_index = similarities.argmax().item()\n",
    "\n",
    "        # Print the most similar response\n",
    "        print(\"Input sentence:\", input_sentence)\n",
    "        print(\"Most tag:\", candidate_responses_tags[most_similar_index])\n",
    "        print(\"Most similar response:\", candidate_responses[most_similar_index])\n",
    "        print(\"similarity:\",similarity)\n",
    "        result = {\n",
    "            \"input_sentence\": input_sentence,\n",
    "            \"tag\": candidate_responses_tags[most_similar_index],\n",
    "            \"content\": candidate_responses[most_similar_index],\n",
    "            \"similarity\" : round(similarity.item(),5)\n",
    "        }\n",
    "        send_json_response(self, '200', result)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    try:\n",
    "        port = 8000\n",
    "        server = HTTPServer(('localhost', port), WebServerHandler)\n",
    "        server.max_body_length = 10 * 1024 * 1024  # set to 10 MB\n",
    "\n",
    "        print(f'Server running on port {port}')\n",
    "        \n",
    "        server.serve_forever()\n",
    "    except KeyboardInterrupt:\n",
    "        print('^C received, shutting down server')\n",
    "        server.socket.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-12-06T07:15:26.549466Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6577]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer(\"shibing624/text2vec-base-chinese\")\n",
    "\n",
    "sentence1_embeddings = model.encode([\"go to the curch\"])\n",
    "# sentence2_embeddings = model.encode([\"你是誰\"])\n",
    "# sentence2_embeddings = model.encode([\"你過得如何\"])\n",
    "sentence2_embeddings = model.encode([\"come on\"])\n",
    "\n",
    "similarity = util.pytorch_cos_sim(sentence1_embeddings, sentence2_embeddings)\n",
    "print(similarity)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T06:42:38.622899Z",
     "start_time": "2023-12-06T06:42:37.128311Z"
    }
   },
   "id": "8eaebfb4aa27e744"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server running on port 8000\n",
      "Input sentence: go to the church\n",
      "Most tag: ASK_TO_PLAY\n",
      "Most similar response: Come on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 53244)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johnny/anaconda3/lib/python3.10/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/Users/johnny/anaconda3/lib/python3.10/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/Users/johnny/anaconda3/lib/python3.10/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/Users/johnny/anaconda3/lib/python3.10/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/Users/johnny/anaconda3/lib/python3.10/http/server.py\", line 433, in handle\n",
      "    self.handle_one_request()\n",
      "  File \"/Users/johnny/anaconda3/lib/python3.10/http/server.py\", line 421, in handle_one_request\n",
      "    method()\n",
      "  File \"/var/folders/8s/9fh2s7w53w1fks_4dpp52tyw0000gn/T/ipykernel_46525/279449740.py\", line 80, in do_POST\n",
      "    print(\"similarity:\", similarities.item())\n",
      "RuntimeError: a Tensor with 10 elements cannot be converted to Scalar\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sentence: go to the church\n",
      "Most tag: ASK_TO_PLAY\n",
      "Most similar response: Come on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 53254)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/johnny/anaconda3/lib/python3.10/socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"/Users/johnny/anaconda3/lib/python3.10/socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/Users/johnny/anaconda3/lib/python3.10/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/Users/johnny/anaconda3/lib/python3.10/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/Users/johnny/anaconda3/lib/python3.10/http/server.py\", line 433, in handle\n",
      "    self.handle_one_request()\n",
      "  File \"/Users/johnny/anaconda3/lib/python3.10/http/server.py\", line 421, in handle_one_request\n",
      "    method()\n",
      "  File \"/var/folders/8s/9fh2s7w53w1fks_4dpp52tyw0000gn/T/ipykernel_46525/279449740.py\", line 80, in do_POST\n",
      "    print(\"similarity:\", similarities.item())\n",
      "RuntimeError: a Tensor with 10 elements cannot be converted to Scalar\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C received, shutting down server\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-06T06:42:34.134983Z",
     "start_time": "2023-12-06T06:41:16.090169Z"
    }
   },
   "id": "49eb88a4e22fb1ee"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5ce5770c3909dacf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
